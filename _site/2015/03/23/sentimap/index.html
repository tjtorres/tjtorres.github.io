<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="This blog details my data science and data visualization projects and thoughts.">

    <title>Inside SentiMap.us: Part 1 - Random Projections</title>

    <link rel="canonical" href="localhost:4000/2015/03/23/sentimap/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Random Projections</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/contact/">Contact</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Post Header -->
<header class="intro-header" style="background-image: url('/img/sentimap.png')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Inside SentiMap.us: Part 1</h1>
                    
                    <h2 class="subheading">A Pythonic How-To on Twitter Sentiment</h2>
                    
                    <span class="meta">Posted by TJ Torres on March 23, 2015</span>
                </div>
            </div>
        </div>
    </div>
	
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <div class="col-lg-9 col-lg-offset-1 col-md-10 col-md-offset-1">

				<h1 id="introduction">Introduction</h1>

<p>This is the first in a series of planned posts describing the building of my web app project <a href="http://sentimap.us">SentiMap.us</a>. The basic premise behind SentiMap is to plot localized trends in mood via realtime sentiment analysis of a geotagged Twitter stream. This post will focus mainly on the backend sentiment analysis portion of the project and take you through streaming tweets, feature extraction, and classification. However, if you get impatient waiting for future posts, the full code is available on <a href="https://github.com/tjtorres/SentiMap">GitHub</a> for you to peruse at your leisure.</p>

<p>Without getting too far into the details just yet, the main functionality behind the sentiment classification, in this case, comes from vectorizing tweets via Word2Vec to construct tweet feature vectors and then training a random forest classifier on a <a href="http://help.sentiment140.com/for-students">pre-classified tweet corpus</a>. We will cover each of these topics in greater detail later, but for now let’s focus on the setup.</p>

<p>The entirety of the coding for the first post will be in python, and will use the following libraries:</p>

<ul>
  <li><a href="https://github.com/tweepy/tweepy">Tweepy</a> (Python library for dealing with the Twitter API)</li>
  <li><a href="http://www.nltk.org">NLTK</a> (Natural Language Toolkit used for stopwords)</li>
  <li><a href="https://radimrehurek.com/gensim/">gensim</a> (Python library containing Word2Vec algorithm)</li>
  <li><a href="http://pandas.pydata.org">Pandas</a> (for managing the Tweet training corpus)</li>
  <li><a href="http://scikit-learn.org/stable/">Scikit-Learn</a> (providing machine learning functionality)</li>
</ul>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>pip install tweepy nltk gensim pandas sklearn
</pre></div>
</div>
</div>

<p>Note that in order to use NLTK’s stop word corpus you must first download it via</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>&gt;&gt;&gt;<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">nltk</span>
&gt;&gt;&gt;nltk.download()
</pre></div>
</div>
</div>

<p>With that out of the way, the basic flow follows two main lines:</p>

<h4 id="training-the-classifier">Training the Classifier</h4>

<ol>
  <li>Load the GoogleNews pre-trained Word2Vec vectors.</li>
  <li>Import and format/clean the Sentiment140 Twitter Corpus.</li>
  <li>Vectorize the training data tweets.</li>
  <li>Train a classifier on the cleaned corpus data (I chose a Random Forest).</li>
</ol>

<h4 id="predicting-tweet-sentiment-from-stream">Predicting Tweet Sentiment From Stream</h4>

<ol>
  <li>Grab JSON formatted output from the Stream endpoint of the Twitter API</li>
  <li>Strip/clean tweet text.</li>
  <li>Vectorize cleaned tweet.</li>
  <li>Predict sentiment and store data in database.</li>
</ol>

<h2 id="representing-words-as-vectors">Representing Words as Vectors</h2>

<p>We’ll start out by training a machine learning classifier to predict tweet sentiment. The general methodology behind any classification scheme is to take a dataset and transform each data point into a vector that, we hope, represents its most salient features with respect to the task at hand. This process of feature extraction can be nearly trivial for some applications, but in general it represents a substantive obstacle with no unique solution.</p>

<p>In the case of natural language processing (NLP), the process of feature extraction for use in sentiment analysis is particularly ill-defined. When we, as people, parse a sentence or phrase we can draw upon years of past experience and contextual clues from countless interactions with language to determine whether said phrase is generally positive, negative, or neutral. For instance, most people would generally decide that the sentence “He is not the brightest crayon in the box.” is reasonably negative. However, without the idiomatic context, the phrase itself might be viewed as merely neutral.</p>

<p>Additionally, taking this lack of context to the extreme we might consider the same phrase where even the order of words (that is the contextual clues in the the text itself) were beyond our knowledge. Or perhaps in it’s ultimate manifestation, the ordering of letters and characters. It’s easy to see the difficulty in deciding anything, other than perhaps letter frequency, about a phrase that has been deconstructed so completely. Yet this is somewhat akin to the world that machines inhabit, having no previous knowledge of language context beyond syntactic rules for translating code documents into binary.</p>

<p>Thus, while there are certainly more naive approaches to constructing vector representations of documents, the big challenge is then to construct systems which simulate the process of learning contextual knowledge. To that end, we will focus on a system of algorithms, called Word2Vec, designed to extract context clues for specific words via the analysis of massive datasets of text.</p>

<p>As much as I’d love to speak a bit about how Word2Vec works (perhaps a future blog post) in gritty technical detail, for now I will point you to a <a href="http://technology.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/">blog post written by a friend of mine</a> which is quite accessible to the lay-person, but contains a large number of technical links at the bottom for those who wish to delve further. Suffice it to say here that Word2Vec “learns” N-dimensional vector representations of words by analyzing and associating words that are less than a certain distance from them in the corpus of training text. At the end of the day we want two words to have vectors that are “close” to each other when it is probabilistically favorable for them to be near each other in a system of documents. For example, a decent metric for determining the “closeness” of vectors is the angle between them which can be easily obtained through use of the inner (or dot) product. Consequently, one might expect that “lion” and “giraffe” are often mentioned within close proximity to one another and thus the angle between their vector representations should be close to zero.</p>

<p>Given the amount of text needed to train these models, it is often advantageous to use large corpuses of words with their pre-trained vectors representations. As the original implementation of Word2Vec was invented by a Google engineer, the codebase, as well as <a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing">pre-trained vector sets</a> can be found on their site <a href="https://code.google.com/p/word2vec/">here</a>. For this example we will use their vectors that have been trained on GoogleNews stories.</p>

<p>Since our vectors are pre-trained we will just need to load the binary file into gensim’s Word2Vec implementation. Vectors for given words are then easily accessible by using the word strings as keys on our model instance. Then we will construct a function to take a string with only letters and whitespace and remove common words of little contextual meaning, called stop words, then output a vector based on the average of the set of vectors that correspond to words in the string.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">gensim</span> <span style="color:#080;font-weight:bold">as</span> gs
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">numpy</span> <span style="color:#080;font-weight:bold">as</span> np
<span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">nltk.corpus</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">stopwords</span>

stop_set = <span style="color:#369;font-weight:bold">set</span>(stopwords.words(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">english</span><span style="color:#710">&quot;</span></span>))

model = gs.models.Word2Vec.load_word2vec_format(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">./GoogleNews-vectors-negative300.bin</span><span style="color:#710">'</span></span>, binary=<span style="color:#069">True</span>)

<span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">phrase2vec</span>(phrase):
    phrase = phrase.lower().split()
    phrase_fil = [w <span style="color:#080;font-weight:bold">for</span> w <span style="color:#080;font-weight:bold">in</span> phrase <span style="color:#080;font-weight:bold">if</span> <span style="color:#080;font-weight:bold">not</span> w <span style="color:#080;font-weight:bold">in</span> stop_set]
    size = <span style="color:#00D">0</span>
    vec = np.zeros(<span style="color:#00D">300</span>)
    <span style="color:#080;font-weight:bold">for</span> word <span style="color:#080;font-weight:bold">in</span> phrase_fil:
        <span style="color:#080;font-weight:bold">try</span>:
            vec= np.add(vec,model[word])
            size+=<span style="color:#00D">1</span>
        <span style="color:#080;font-weight:bold">except</span>:
            <span style="color:#080;font-weight:bold">pass</span>
    <span style="color:#080;font-weight:bold">if</span> size==<span style="color:#00D">0</span>:
        size=<span style="color:#00D">1</span>
    <span style="color:#080;font-weight:bold">return</span> np.divide(vec,size)

</pre></div>
</div>
</div>

<p>We now have a nice function for vectorizing tweets, once they have been properly formatted.</p>

<h2 id="cleaning-the-data">Cleaning the Data</h2>

<p>Next, we’ll need to get some training data to run our feature extraction method on. Though there are several Twitter sentiment corpora on the web, many of them sacrifice sample size for accuracy of classification of the training set. Since we are dealing with the potentially very powerful, but somewhat nebulous, concept of word vectors we should choose instead to err on the side of a much larger training set, with perhaps a slight hit to classification accuracy. This can be accomplished by creating heuristics for classification rather than relying on manual techniques. The <a href="http://help.sentiment140.com/for-students/">Sentiment 140 Corpus</a> constructs its sentiment classification heuristic on tweets that contain emoticons. Of the tweets that contain emoticons, those that contain mostly positive emoticons are classified as such, and the same goes for the negative set.</p>

<p>With this heuristic one can immediately automate the data classification task for the training set, which allows for a far greater sample size (in this case 1.6M tweets), at the expense of a possible drop in accuracy.</p>

<p>To analyze and clean our data we’re going to work with Pandas, but first let’s take a brief look at the format of the training data.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>$head -10 training.1600000.processed.noemoticon.csv

&quot;0&quot;,&quot;1467810369&quot;,&quot;Mon Apr 06 22:19:45 PDT 2009&quot;,&quot;NO_QUERY&quot;,&quot;_TheSpecialOne_&quot;,&quot;@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D&quot;
&quot;0&quot;,&quot;1467810672&quot;,&quot;Mon Apr 06 22:19:49 PDT 2009&quot;,&quot;NO_QUERY&quot;,&quot;scotthamilton&quot;,&quot;is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!&quot;
&quot;0&quot;,&quot;1467810917&quot;,&quot;Mon Apr 06 22:19:53 PDT 2009&quot;,&quot;NO_QUERY&quot;,&quot;mattycus&quot;,&quot;@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds&quot;
&quot;0&quot;,&quot;1467811184&quot;,&quot;Mon Apr 06 22:19:57 PDT 2009&quot;,&quot;NO_QUERY&quot;,&quot;ElleCTF&quot;,&quot;my whole body feels itchy and like its on fire &quot;
$
</pre></div>
</div>
</div>

<p>From the first few lines you can see the general format of the data and should notice several things. For instance the training data file doesn’t have a header, so we’ll have to name the columns ourselves. Also, the text of the tweets has been formatted to remove emoticons, but still contains plenty of errant strings like URLs and @name tags we’ll need to remove before proceeding to vectorize them.</p>

<p>First let’s import the csv file and store it as a dataframe.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">pandas</span> <span style="color:#080;font-weight:bold">as</span> pd
name_list = [<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">sentiment</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">id</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">time</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">query</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">user</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">text</span><span style="color:#710">'</span></span>]
df = pd.read_csv(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">training.1600000.processed.noemoticon.csv</span><span style="color:#710">&quot;</span></span>,\
                 header=<span style="color:#069">None</span>, names= name_list)
</pre></div>
</div>
</div>

<p>Now we’ll create a function that takes a string and strips it down to only the text content we care about, removing URLs, names, emoji character sets, and “#” part of the hashtags. We can also optimize our data to be more uniform by taking repeated instances of letters, as in the string “loooooooooove”, and transforming them down to 2 at most. This is best accomplished using python’s regular expressions module. I’ll construct the function here, keeping things a bit more long form for the sake of readability.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">re</span>

<span style="color:#777">#compile regular expressions that match repeated characters and emoji unicode</span>
emoji = re.compile(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">u</span><span style="color:#710">'</span><span style="color:#D20">[^</span><span style="color:#b0b">\x00</span><span style="color:#D20">-</span><span style="color:#b0b">\x7F</span><span style="color:#b0b">\x80</span><span style="color:#D20">-</span><span style="color:#b0b">\xFF</span><span style="color:#b0b">\u0100</span><span style="color:#D20">-</span><span style="color:#b0b">\u017F</span><span style="color:#b0b">\u0180</span><span style="color:#D20">-</span><span style="color:#b0b">\u024F</span><span style="color:#b0b">\u1E00</span><span style="color:#D20">-</span><span style="color:#b0b">\u1EFF</span><span style="color:#D20">]</span><span style="color:#710">'</span></span>,re.UNICODE)
multiple = re.compile(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">&quot;</span><span style="color:#D20">(.)</span><span style="color:#D20">\1</span><span style="color:#D20">{1,}</span><span style="color:#710">&quot;</span></span>, re.DOTALL)

<span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">format</span>(tweet):

    <span style="color:#777">#strip emoji</span>
    stripped = emoji.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#710">'</span></span>,elem[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">text</span><span style="color:#710">'</span></span>])
    
    <span style="color:#777">#strip URLs</span>
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">'</span><span style="color:#D20">http[s]?[^</span><span style="color:#D20">\s</span><span style="color:#D20">]+</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#710">'</span></span>, stripped)
    
    <span style="color:#777">#strip &quot;@name&quot; components</span>
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">'</span><span style="color:#D20">(@[A-Za-z0-9</span><span style="color:#D20">\_</span><span style="color:#D20">]+)</span><span style="color:#710">'</span></span> , <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#710">&quot;</span></span> ,stripped)
    
    <span style="color:#777">#strip html '&amp;amp;', '&amp;lt;', etc.  </span>
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">'</span><span style="color:#D20">[</span><span style="color:#D20">\&amp;</span><span style="color:#D20">].*;</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#710">'</span></span>,stripped)
    
    <span style="color:#777">#strip punctuation</span>
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">'</span><span style="color:#D20">[#|</span><span style="color:#D20">\!</span><span style="color:#D20">|</span><span style="color:#D20">\-</span><span style="color:#D20">|</span><span style="color:#D20">\+</span><span style="color:#D20">|:|//]</span><span style="color:#710">'</span></span>, <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20"> </span><span style="color:#710">&quot;</span></span>, stripped)
    
    <span style="color:#777">#strip the common &quot;RT&quot;</span>
    stripped = re.sub( <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">RT.</span><span style="color:#710">'</span></span>,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#710">'</span></span>, stripped)
    
    <span style="color:#777">#strip whitespace down to one.</span>
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">[</span><span style="color:#D20">\s</span><span style="color:#D20">]+</span><span style="color:#710">'</span></span> ,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20"> </span><span style="color:#710">'</span></span>, stripped).strip()
    
    <span style="color:#777">#strip multiple occurrences of letters</span>
    stripped = multiple.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#E40">r</span><span style="color:#710">&quot;</span><span style="color:#D20">\1</span><span style="color:#D20">\1</span><span style="color:#710">&quot;</span></span>, stripped)
    
    <span style="color:#777">#strip all non-latin characters</span>
    <span style="color:#777">#if we wish to deal with foreign language tweets, we would need to first </span>
    <span style="color:#777">#translate them before taking this step.</span>
    
    stripped = re.sub(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">[^a-zA-Z0-9|</span><span style="color:#b0b">\'</span><span style="color:#D20">]</span><span style="color:#710">'</span></span>, <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20"> </span><span style="color:#710">&quot;</span></span>, stripped).strip()
    
    <span style="color:#080;font-weight:bold">return</span> stripped
</pre></div>
</div>
</div>

<p>Take a look at <a href="https://docs.python.org/2/howto/regex.html">Python’s RegEx HOW-TO</a> if you’re confused on the above format. You can also test them out yourself by visiting <a href="http://regexr.com">Regexr</a>.</p>

<h2 id="training-the-classifier-1">Training the Classifier</h2>

<p>Now we’re ready to train our classifier. Let’s start off by making an array of feature vectors for our training data, as well as an array of target values for the sentiment.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#777">#initialize a numpy array to the proper shape and a counter. </span>
training_data = np.zeros((df.shape[<span style="color:#00D">0</span>],<span style="color:#00D">300</span>))
counter = <span style="color:#00D">0</span>
<span style="color:#777">#add vectorized tweet text to numpy array.</span>
<span style="color:#080;font-weight:bold">for</span> tweet <span style="color:#080;font-weight:bold">in</span> df[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">text</span><span style="color:#710">'</span></span>].values:

        filtered = format(tweet)
        vectorized = phrase2vec(filtered)
        training_data[counter] = vectorized
        counter+=<span style="color:#00D">1</span>
        
training_target = df[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">sentiment</span><span style="color:#710">'</span></span>].values
</pre></div>
</div>
</div>

<p>Now we simply pick which ML algorithm we wish to train. In this case I will be using a random forest classifier. Once we train our model we can then easily export the results using scikit-learn’s joblib function, which operates on Python’s Pickle package (say that 5 times fast) to dump our Python classifier model to a file.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.ensemble</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">RandomForestClassifier</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.externals</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">joblib</span>

cl = RandomForestClassifier()

cl.fit(training_data, training_target)

joblib.dump(cl,<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">Pickle/rfc.pkl</span><span style="color:#710">'</span></span>)

</pre></div>
</div>
</div>

<p>That’s basically it for training. So far we have trained and exported a classifier to use in the future for predicting tweet sentiment. At this point it would normally be necessary to validate the model via the method of your choice. Scikit-learn has some nice cross-validation functionality for just this purpose, or you can grab the test data from the same Sentiment 140 folder and begin your testing metrics. For simple classification tasks like this I find F-scores to be rather useful. Also you should note that we have only used the default configured random forest classifier here, and there are many options with which to performance optimize your individual setup.</p>

<h2 id="streaming-and-predicting-tweets">Streaming and Predicting Tweets</h2>

<p>Now that we have a model, we can move to predicting a tweet stream in realtime. In order to start streaming tweets, we’ll use a nice Python package called Tweepy, which interfaces with the Twitter API and allows us to focus our attention on the task at hand rather than dealing with Oauth validation. You will need to get some credentials before we can start, so head over to <a href="https://apps.twitter.com">Twitter’s application page</a> and register your own “app” to receive access credentials.</p>

<p>Once you’ve got your credentials and installed the Tweepy we can proceed to setting up a streaming client. In this example I’ll set one up that outputs the sentiment-valued stream to file. First we need to construct a <code>Listener</code> class that inherits from<code>tweepy.streaming.StreamListener</code>. We’ll also be handling JSON, so we need to import Python’s JSON module as well. We will use the on_data method to perform a task every time we receive a tweet.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">tweepy.streaming</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">StreamListener</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">tweepy</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">OAuthHandler</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">tweepy</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">Stream</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">json</span>
<span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">datetime</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">datetime</span>
<span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">time</span>




<span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">get_sentiment</span>(text, stop , model, trained_classifier):
    cl = trained_classifier
    vec = phrase2vec(text,stop,model)
    pred = cl.predict_proba(vec)[<span style="color:#00D">0</span>][<span style="color:#00D">1</span>]
    <span style="color:#080;font-weight:bold">return</span> pred
        

<span style="color:#080;font-weight:bold">class</span> <span style="color:#B06;font-weight:bold">Listener</span>(StreamListener):
    
    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">__init__</span>(<span style="color:#069">self</span>, classifier, stops, model,start):
        <span style="color:#069">self</span>.cl = classifier
        <span style="color:#069">self</span>.stop = stops
        <span style="color:#069">self</span>.model = model
                <span style="color:#069">self</span>.start = start
    
        
    
    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">on_data</span>(<span style="color:#069">self</span>, data):
        <span style="color:#777">#parse json from data event</span>
        elem = json.loads(data)
                
        <span style="color:#080;font-weight:bold">with</span> <span style="color:#369;font-weight:bold">open</span>(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">./Data/{0}</span><span style="color:#710">&quot;</span></span>.format(sys.argv[<span style="color:#00D">1</span>]),<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">a</span><span style="color:#710">'</span></span>) <span style="color:#080;font-weight:bold">as</span> f:
            writer = csv.writer(f,codecs.getwriter(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">utf-8</span><span style="color:#710">'</span></span>)(sys.stdout))
            tweet = elem[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">text</span><span style="color:#710">'</span></span>]
            <span style="color:#080;font-weight:bold">if</span> elem[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">lang</span><span style="color:#710">'</span></span>] ==  <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">en</span><span style="color:#710">'</span></span> <span style="color:#080;font-weight:bold">or</span> elem[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">lang</span><span style="color:#710">'</span></span>] ==  <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">en-gb</span><span style="color:#710">'</span></span>:
                filtered = format(tweet)
        
        
                <span style="color:#080;font-weight:bold">if</span> <span style="color:#369;font-weight:bold">len</span>(filtered.split()) &gt; <span style="color:#00D">2</span>:
                    sentiment = get_sentiment(filtered, <span style="color:#069">self</span>.stop, <span style="color:#069">self</span>.model, <span style="color:#069">self</span>.cl)
                    
                    writer.writerow( [tweet,
                                      filtered,
                                      sentiment,
                                      datetime.utcnow()])
        
    
                            
                    
                    
        t1 = time.time()
        t0 = <span style="color:#069">self</span>.start
        <span style="color:#080;font-weight:bold">if</span> t1-t0 &lt;= <span style="color:#369;font-weight:bold">float</span>(sys.argv[<span style="color:#00D">2</span>])*<span style="color:#60E">3600.</span>:
            sys.stdout.write(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#b0b">\r</span><span style="color:#D20">{0}</span><span style="color:#710">&quot;</span></span>.format(t1-t0))
            sys.stdout.flush()
            <span style="color:#080;font-weight:bold">return</span> <span style="color:#069">True</span>
        <span style="color:#080;font-weight:bold">else</span>:
            <span style="color:#080;font-weight:bold">print</span> <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#b0b">\n</span><span style="color:#D20">Time's Up!</span><span style="color:#710">&quot;</span></span>
            <span style="color:#080;font-weight:bold">return</span> <span style="color:#069">False</span>
            
            
            
    <span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">on_error</span>(<span style="color:#069">self</span>, status):
        <span style="color:#080;font-weight:bold">print</span> status
</pre></div>
</div>
</div>

<p>This class then takes incoming tweets and writes them to a file specified as the first argument. The second argument is reserved for the time (in hours) one wishes to keep the stream alive. You can easily edit this to continue indefinitely if desired.</p>

<p>From here on in we must merely load in models and setup the stream with our credentials.</p>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre>
<span style="color:#080;font-weight:bold">if</span> __name__ == <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">__main__</span><span style="color:#710">'</span></span>:

    <span style="color:#777">####################Variables that contain the user credentials for the Twitter API </span>
    access_token = <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">ACCESS_TOKEN</span><span style="color:#710">&quot;</span></span>
    access_token_secret = <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">ACCESS_TOKEN_SECRET</span><span style="color:#710">&quot;</span></span>
    consumer_key = <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">CONSUMER_KEY</span><span style="color:#710">&quot;</span></span>
    consumer_secret = <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">CONSUMER_SECRET</span><span style="color:#710">&quot;</span></span>
    <span style="color:#777">#########################################################</span>
    
    <span style="color:#777">#Write file header</span>
    f=<span style="color:#369;font-weight:bold">open</span>(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">./Data/{0}</span><span style="color:#710">&quot;</span></span>.format(sys.argv[<span style="color:#00D">1</span>]),<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">w</span><span style="color:#710">'</span></span>)
    f.write(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">original_text,filtered_output,sentiment,time </span><span style="color:#b0b">\n</span><span style="color:#710">&quot;</span></span>)
    f.close()
    
    
    <span style="color:#080;font-weight:bold">print</span> <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Loading Classifier...</span><span style="color:#b0b">\n</span><span style="color:#b0b">\n</span><span style="color:#710">&quot;</span></span>
    
    <span style="color:#777">#load trained sklearn classifier</span>
    cl=joblib.load(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">Pickle/rfc.pkl</span><span style="color:#710">'</span></span>)
    
    <span style="color:#080;font-weight:bold">print</span> <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Classifier Loaded...loading model...</span><span style="color:#b0b">\n</span><span style="color:#b0b">\n</span><span style="color:#710">&quot;</span></span>
    
    <span style="color:#777">#load w2v vectors from GoogleNews training set. </span>
    model= gs.models.Word2Vec.load_word2vec_format(
           <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">./static/Data/GoogleNews-vectors-negative300.bin</span><span style="color:#710">'</span></span>,binary=<span style="color:#069">True</span>)
    
    
    <span style="color:#080;font-weight:bold">print</span> <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Model Loaded...</span><span style="color:#b0b">\n</span><span style="color:#b0b">\n</span><span style="color:#710">&quot;</span></span>
    
    <span style="color:#777">#load set of stop words</span>
    stop_set = <span style="color:#369;font-weight:bold">set</span>(stopwords.words(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">english</span><span style="color:#710">&quot;</span></span>))
    
    start = time.time()
    
    l = Listener(cl,stop_set,model,start)
    
    <span style="color:#777">#This handles Twitter authentication and the connection to Twitter Streaming API</span>
    
    <span style="color:#777">#Oauth Handling</span>
    auth = OAuthHandler(consumer_key, consumer_secret)
    auth.set_access_token(access_token, access_token_secret)
    
    stream = Stream(auth, l)
    <span style="color:#080;font-weight:bold">print</span> <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">&quot;</span><span style="color:#D20">Listening...</span><span style="color:#710">&quot;</span></span>
    
    <span style="color:#777">#initiate stream</span>
    stream.sample()
    
</pre></div>
</div>
</div>

<p>When we run the file <code>python path_to_script.py output_file_name time</code> we should then see our file being populated with tweets and their corresponding sentiments.</p>

<h1 id="more-to-come">More to Come</h1>
<p>This concludes the first post on SentiMap.us. Hopefully you’ve gained a basic understanding of the nuts and bolts behind realtime sentiment analysis for twitter streams.</p>

<p>In the next post we will cover using MongoDB to hold fixed size collections of tweets, setting up a basic web server using Flask, and serving out data to servers using the PubSub messaging queue paradigm.</p>



                <hr>

                <ul class="pager">
                    
                    
                </ul>

            </div>
        </div>
    </div>
<div id="disqus_thread" class="col-lg-9 col-lg-offset-1 col-md-10 col-md-offset-1"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'orthogonalprojections';
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</article>

<hr>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/tjtorres">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Random Projections 2015</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>


</body>

</html>
